\section{Introduction}

Atmospheric spectral radiance distributions, for ultraviolet (UV), infrared (IR) and visible spectra, for the entire sky, are often simplified into a single downwelling irradiance measurement, mainly because whole sky spectral radiance is difficult and expensive to measure in real-time and complicated to model. Yet precise radiance distributions are still very much needed for accurate calculations in real-time applications of building performance \citep{hensen_buildingperformance, chandrasekhar_radiative, jakica_survey}, environmental science \citep{lopez-alvarez_using_2008}, photo-voltaic (PV) alignment \citep{smith_tilt}, and physically based rendering \citep{jakob_mitsuba, hosek_model, satylmys_ann}. Unlike irradiance, spectral radiance is directional and should be available for any point in the sky, as simulations are affected by the angle of incidence of spectral sky energy and receiving surface.

We present a data-driven machine learning approach to estimate spectral radiance for any point in a clear sky to within acceptable tolerances for real-time applications. We use high dynamic range (HDR) photographs of the sky and validated spectral radiance measurements captured throughout an entire year by a custom sky scanning framework \citep{kider_framework_2014}, to train models that learn a relationship between capture time, sky appearance, and underlying energy (350-1780 nm). The primary contribution of our research is the reconstruction of high-dimensional atmospheric spectral radiance for every single point in a clear sky, including non-visible spectra (UV and near IR), given only a low-dimensional digital photograph of the sky and its capture time. We show that a clear sky photograph can be used to predict non-visible (and visible) atmospheric radiance energy.

Notable previous data-driven approaches to model skylight include \citet{tohsing_validation_2014}, \citet{saito_estimation_2016}, and \citet{lopez-alvarez_using_2008, cazorla_using_2008, cazorla_development_2008}. Tohsing et. al leveraged ground-based sky radiance photographs and a non-linear regression model per wavelength to reconstruct only the visible spectrum. Saito et. al used total ozone column readings, camera color matching functions, and a linear algebra approach to predict a subset of visible for a single point in the sky. Cazorla et al. used neural networks, genetic algorithms, and regression models for specific points in the sky. Much of that work was performed on limited sets of data, and in some cases only a few hours of single sky cover used for training \citep{tohsing_validation_2014}. Our dataset is much more comprehensive. And our methods predict a wider, more useful spectral range, for every point in the sky. Furthermore, we show the reconstruction of non-visible energy from photometric inputs.

In this work, four separate regression models are developed through machine learning, with a combination of input features from correlated sky imagery and validated spectral radiance measurements. A series of new experiments are performed to test model effectiveness and efficiency with regards to changes in exposure, sky sample color model, and spectrum resolution. A tool is developed that uses a single model to predict spectral radiance distributions for every point of a hemispherical sky, at 1 nm resolution. Spectral radiance distributions are validated against libRadtran, a validated radiative transfer software package for atmospheric science \citep{emde_libradtran, buras_2011, mayer_2005, kylling_1995, dahlback_1991, stamnes_1988}.

We explain in \autoref{ssec:skycover} that this work focuses on clear skies by design. In our initial work \citep{delrocco_spie}, we showed that regression models were not the best solution for scattered and overcast skies, despite the fact that one of the models showed promise. We believe a more complex machine-learning solution is needed to understand the more complicated patterns behind cloudy sky radiance. In contrast to more traditional atmospheric models, we purposely omit aerosol optical depth (AOD) and trace gas measurements to test viability of our methods today in real-time applications (commodity building monitoring systems, residential solar installations, rendering pipelines, etc.), which often do not have access to accurate sky measurements needed for complex physically-based solutions. Our proposed methods can accommodate readily available AOD and other atmospheric measurements as training and prediction features. Such features may even help our models adapt to localized turbidity.

% \citet{steven_standard_1977} found \textit{``departures due to variation in atmospheric turbidity [\dots] to be small,''} and \citet{willers_radiometry} noted that \textit{``aerosol attenuation in the atmosphere has a relatively weak spectral variation.''}

The remainder of this paper is organized as follows. First, related work is presented in \autoref{sec:background}. Our measurements and engineered data is detailed in \autoref{sec:data}. We present our methods and experiments in \autoref{sec:method}, results in \autoref{sec:results}, and validations in \autoref{sec:validation}. Finally, conclusions and future work are presented in \autoref{sec:conclusion}. 

